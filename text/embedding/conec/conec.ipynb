{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConEc (Context Encoders), an extension of word2vec"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is a Python3 implementation of the following paper - \n",
    "Franziska Horn, Context encoders as a simple but powerful extension of word2vec, Proceedings of the 2nd Workshop on Representation Learning for NLP, Association for Computational Liguistics 2017, Pages 10-14"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This implementation mitigates the shortcomings of word2vec in that word2vec learns only a single representation (embedding) for a word, but it is possible to have a word which means different things in different context..\n",
    "For Ex. Washington (US State) vs Washington (Former President)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This code can be used to train, evaluate an use Context Encoders (ConEc), a powerful context-aware extension of word2vec. This can be used to generate text embeddings for a word with multiple meanings or for Out-Of-Vocabulary (OOV) words by using a trained model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code implements the following procedure -\n",
    "- Use CBOW word2vec model with negative sampling objective\n",
    "- Train the model on \"text8\" , \"OneBilCorpus\" or \"conll2003\" datasets\n",
    "- Multiply the trained word2vec embeddings with the word's average context vectors (CVs)\n",
    "- A word has global CV and local CV\n",
    "- Choice of alpha in the equation mentioned in the paper determines the emphasis on the word's local context\n",
    "\n",
    "Download the conec folder from this repository and import the conec class into your script\n",
    "\n",
    "Follow instructions given in README.md for more details about the Pre-requisites to run this notebook\n",
    "\n",
    "This notebook trains the context2vec model on limited data due to space constraints, specifically 162000 words and 162 sentences from the \"text8\" dataset. To train it on all of the \"text8\" dataset, please change the following line \n",
    "\n",
    "`while count <= 118:` \n",
    "\n",
    "to \n",
    "\n",
    "`while True:` \n",
    "\n",
    "in `conec.py`\n",
    "\n",
    "It gives a very low accuracy for the Google Analogy Task as its trained on a very small chunk of vocabulary from \"text8\".\n",
    "\n",
    "Follow the results present in the results/ folder to find out the actual accuracies attrained by `conec` for the Google Analogy Task and CoNLL 2003 NER Task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conec import conec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a conec class object, context2vec\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conec object created ... \n",
      "Use this object to get text embeddings or text similarity...\n"
     ]
    }
   ],
   "source": [
    "context2vec = conec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Loading Dataset\n",
    "---\n",
    "Ensure text8/OneBillionCorpus/CoNLL 2003 data is downloaded and present in /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset ....\n",
      "Dataset loaded into conec object ....\n"
     ]
    }
   ],
   "source": [
    "context2vec.read_Dataset('text8', 'data/text8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training \n",
    "Train the conec object on 5 iterations of word2vec model with negative modeling, \n",
    "followed by introducing the context vectors to this pre-trained model\n",
    "Modify the iterations, modelType (\"cbow\" or \"sg\") and embedding dimesion (embed_dim) as required\n",
    "Here, we are only training the model for 1 iteration to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-01 03:50:36,078 : INFO : collecting all words and their counts\n",
      "2019-05-01 03:50:36,085 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 unique words\n",
      "2019-05-01 03:50:36,254 : INFO : collected 16438 unique words from a corpus of 162000 words and 162 sentences\n",
      "2019-05-01 03:50:36,263 : INFO : total of 3878 unique words after removing those with count < 5\n",
      "2019-05-01 03:50:36,265 : INFO : constructing a table with noise distribution from 3878 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conec object being trained using text8 dataset present in the directory ../../../../examples/data/text8 ....\n",
      "Creating word2vec model ....\n",
      "<conec.Text8Corpus object at 0x7f67d72c1cf8>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-01 03:51:42,827 : INFO : training model on 3878 vocabulary and 200 features\n",
      "2019-05-01 03:52:03,033 : INFO : PROGRESS: at 47.22% words, alpha 0.00500, 3310 words/s\n",
      "2019-05-01 03:52:23,063 : INFO : PROGRESS: at 97.58% words, alpha 0.00500, 3435 words/s\n",
      "2019-05-01 03:52:24,031 : INFO : training on 141635 words took 41.2s, 3437 words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the word2vec model on multiple iterations ....\n",
      "PROGRESS: at sentence #0, processed 0 words and 0 unique words\n",
      "collected 16438 unique words from a corpus of 162000 words and 162 sentences\n",
      "PROGRESS: at sentence #0\n",
      "PROGRESS: through with all the sentences\n",
      "Saving context2vec model trained on text8 dataset in the following file - data/text8_cbow_200_hs0_neg13_seed3_it1.model\n",
      "Model for ../../../../examples/data/text8 dataset saved as data/text8_cbow_200_hs0_neg13_seed3_it1.model in the data/ folder\n"
     ]
    }
   ],
   "source": [
    "context2vec.train(iterations=1, saveInterm=False, modelType=\"cbow\", embed_dim=200 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the embedding of a word\n",
    "---\n",
    "Use the model trained above to get the embeddings for any word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16531803, -0.10039496,  0.0074003 , -0.09941176,  0.07194029,\n",
       "       -0.05663242,  0.04278717,  0.0274874 , -0.05531411, -0.10412723,\n",
       "       -0.03567853,  0.12549633,  0.01547575, -0.01862101,  0.01271429,\n",
       "        0.02227433, -0.03902028,  0.09761431, -0.02327678, -0.01857079,\n",
       "        0.06608818,  0.03408823,  0.00421464,  0.06498237,  0.00841683,\n",
       "       -0.00333358,  0.00111326,  0.06494229, -0.03110866, -0.12265436,\n",
       "        0.01439275, -0.005578  , -0.02623828, -0.00900803,  0.1049694 ,\n",
       "        0.10527257,  0.08490574,  0.05287833,  0.08795646,  0.06210937,\n",
       "       -0.0152501 ,  0.23809971, -0.02945294,  0.03858227,  0.03797628,\n",
       "        0.00498829,  0.04977058, -0.07361304, -0.12650932,  0.03004827,\n",
       "        0.05253399, -0.1063354 , -0.02225152,  0.04144626, -0.0713333 ,\n",
       "       -0.04629956,  0.06722289,  0.08018234, -0.06080223,  0.01653811,\n",
       "       -0.02749066, -0.0229704 , -0.13580119,  0.04224365, -0.09832591,\n",
       "       -0.02508853, -0.06136944,  0.06106324,  0.06571213, -0.07697889,\n",
       "        0.03057528, -0.21975355, -0.13595898,  0.08421567, -0.08184387,\n",
       "        0.02255733,  0.0546169 ,  0.05183218, -0.02207429, -0.07196692,\n",
       "       -0.0893088 , -0.03495286,  0.00565578, -0.05307465,  0.09908399,\n",
       "        0.01136816,  0.01728484,  0.10492369,  0.01842306, -0.04144125,\n",
       "        0.04028116, -0.11708585, -0.00297153, -0.01345331, -0.15326196,\n",
       "       -0.05512328, -0.0409887 ,  0.05529917, -0.06146865, -0.08295865,\n",
       "        0.03628625,  0.01850622, -0.0521498 , -0.06867491,  0.01084288,\n",
       "        0.05734882, -0.01977781, -0.06128978,  0.03687638,  0.0066153 ,\n",
       "        0.03521554,  0.02881068,  0.04793613,  0.20550346, -0.03542678,\n",
       "       -0.04515067,  0.03147245, -0.08607456,  0.18897712,  0.1737811 ,\n",
       "        0.00907838, -0.08861139,  0.15784796, -0.02785064, -0.11000211,\n",
       "       -0.00630828,  0.01824563, -0.03352376,  0.0363132 , -0.00172226,\n",
       "        0.04025445, -0.05708995, -0.02908091, -0.00425838, -0.02200084,\n",
       "       -0.08396865,  0.04284532, -0.01337436,  0.01246591,  0.07342561,\n",
       "        0.01526728, -0.00556679,  0.02977265, -0.13580872,  0.02119743,\n",
       "       -0.00577964,  0.0432151 , -0.11423435,  0.11134996, -0.0302969 ,\n",
       "        0.03021376, -0.04132271, -0.0463831 ,  0.15311933, -0.02711532,\n",
       "       -0.0304926 ,  0.02120837, -0.01500201, -0.0270914 ,  0.02207863,\n",
       "        0.12816668,  0.06705797, -0.04125853,  0.11990487, -0.11816006,\n",
       "        0.11639795, -0.03425664, -0.02518117,  0.00860735,  0.01519425,\n",
       "        0.01454588,  0.10984457,  0.07188044, -0.04424711, -0.02936053,\n",
       "       -0.01676091,  0.00684831, -0.07531648, -0.00309807, -0.06117681,\n",
       "        0.04047308, -0.00068895, -0.05626859,  0.00164945, -0.04257214,\n",
       "       -0.03974314, -0.0187097 ,  0.12856996,  0.00352166,  0.07940024,\n",
       "        0.05632431, -0.00029119,  0.01663224,  0.08689787, -0.1039005 ,\n",
       "        0.02798238,  0.05882277, -0.12190544, -0.04353053, -0.02329021])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context2vec.predict_embedding(\"student\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the average embedding of a sentence\n",
    "---\n",
    "Use the model trained above to predict the embedding of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15852345, -0.12578668, -0.01444203, -0.10126745,  0.1023228 ,\n",
       "       -0.03415585,  0.03266247,  0.00875758, -0.05765506, -0.0905843 ,\n",
       "       -0.0126076 ,  0.14165781, -0.00206613, -0.02467626,  0.01630537,\n",
       "        0.01781283, -0.05047987,  0.11270444, -0.00788195, -0.03575283,\n",
       "        0.07065628,  0.03803026,  0.00316418,  0.0641703 ,  0.01651335,\n",
       "        0.01152376, -0.03238369,  0.06772912, -0.03998572, -0.11205994,\n",
       "        0.02399351,  0.0089479 , -0.02309657, -0.02279564,  0.090577  ,\n",
       "        0.09138416,  0.08767302,  0.07333575,  0.11559842,  0.0603927 ,\n",
       "       -0.01774923,  0.21608242, -0.0326739 ,  0.03193534,  0.04408792,\n",
       "        0.01029744,  0.05784287, -0.08015395, -0.1304327 ,  0.02889983,\n",
       "        0.04627755, -0.09095402, -0.02769028,  0.02879271, -0.05120329,\n",
       "       -0.06675243,  0.06470329,  0.03837215, -0.04942747,  0.02869307,\n",
       "       -0.05720734, -0.01412808, -0.15331699,  0.03162723, -0.10662205,\n",
       "       -0.03688817, -0.05528343,  0.03763501,  0.06446529, -0.0619736 ,\n",
       "        0.00610367, -0.24211786, -0.10572711,  0.09241855, -0.09211388,\n",
       "        0.02744864,  0.06666481,  0.04962266, -0.04096894, -0.07297033,\n",
       "       -0.06245811, -0.045016  , -0.00092393, -0.02553889,  0.11384331,\n",
       "       -0.00199146,  0.02780551,  0.08560026,  0.03738708, -0.01105948,\n",
       "        0.05984432, -0.0998927 ,  0.02209128, -0.01175809, -0.12847759,\n",
       "       -0.05525833, -0.00566621,  0.05078886, -0.05036944, -0.05947599,\n",
       "        0.05095039,  0.01117518, -0.07665979, -0.04892088, -0.01397568,\n",
       "        0.05815556, -0.01623879, -0.04937951,  0.03997462,  0.01524303,\n",
       "        0.03376176,  0.03193354,  0.0399302 ,  0.18155231, -0.02669012,\n",
       "       -0.04704867,  0.01549114, -0.06860573,  0.18545506,  0.18317172,\n",
       "        0.01295903, -0.06675061,  0.17382598, -0.01794822, -0.12035635,\n",
       "       -0.0242107 ,  0.0025653 , -0.02729695,  0.02689567,  0.00227582,\n",
       "        0.05272339, -0.08084663, -0.05254249,  0.00802731, -0.00236232,\n",
       "       -0.09363926,  0.01657871, -0.04012929,  0.01885613,  0.04159625,\n",
       "        0.03685067, -0.03199106,  0.01302077, -0.15255375,  0.0145883 ,\n",
       "        0.00135061,  0.04351214, -0.10563432,  0.10637639, -0.03802707,\n",
       "        0.04089313, -0.03306806, -0.07272956,  0.13399649,  0.00066241,\n",
       "       -0.05413016, -0.01075846,  0.02556661, -0.02050566, -0.01218107,\n",
       "        0.16173204,  0.07916267, -0.03934139,  0.10661311, -0.09163503,\n",
       "        0.12298071, -0.04289186, -0.03769167, -0.00454131, -0.0024317 ,\n",
       "        0.00244478,  0.14423111,  0.07157604, -0.00759179, -0.0392244 ,\n",
       "       -0.03564204,  0.02575656, -0.08360607,  0.02118465, -0.03102414,\n",
       "        0.05046537,  0.02921282, -0.06948919, -0.020007  , -0.06431966,\n",
       "       -0.03830216, -0.05030216,  0.1145968 ,  0.01494211,  0.08186289,\n",
       "        0.05736359, -0.01604333,  0.01868335,  0.07007119, -0.0841063 ,\n",
       "       -0.00424476,  0.06416323, -0.12561105, -0.02140693, -0.02522045])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context2vec.predict_sent_embedding(\"This is a great class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity between words using their embeddings\n",
    "---\n",
    "Obtain the similarity between two words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9441206497249871"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context2vec.predict_similarity(\"student\", \"students\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity between sentences using their average embeddings\n",
    "---\n",
    "Obtain the similarity between two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9941471168338919"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context2vec.predict_sent_similarity(\"I am a girl\", \"I am a woman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation on Google Analogy Dataset\n",
    "---\n",
    "Evaluate the trained model on Google Analogy Dataset\n",
    "\n",
    "Ensure questions-words.txt is present in the data/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital-common-countries: 0.0% (0/20)\n",
      "capital-world: 0.0% (0/15)\n",
      "currency: 0.0% (0/4)\n",
      "city-in-state: 4.0% (1/25)\n",
      "family: 4.2% (3/72)\n",
      "gram1-adjective-to-adverb: 0.0% (0/42)\n",
      "gram2-opposite: 0.0% (0/2)\n",
      "gram3-comparative: 0.0% (0/110)\n",
      "gram4-superlative: 0.0% (0/56)\n",
      "gram5-present-participle: 0.0% (0/132)\n",
      "gram6-nationality-adjective: 0.0% (0/177)\n",
      "gram7-past-tense: 0.0% (0/132)\n",
      "gram8-plural: 0.0% (0/90)\n",
      "gram9-plural-verbs: 0.0% (0/132)\n",
      "total: 0.4% (4/1009)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'section': 'capital-common-countries', 'correct': 0, 'incorrect': 20},\n",
       " {'section': 'capital-world', 'correct': 0, 'incorrect': 15},\n",
       " {'section': 'currency', 'correct': 0, 'incorrect': 4},\n",
       " {'section': 'city-in-state', 'correct': 1, 'incorrect': 24},\n",
       " {'section': 'family', 'correct': 3, 'incorrect': 69},\n",
       " {'section': 'gram1-adjective-to-adverb', 'correct': 0, 'incorrect': 42},\n",
       " {'section': 'gram2-opposite', 'correct': 0, 'incorrect': 2},\n",
       " {'section': 'gram3-comparative', 'correct': 0, 'incorrect': 110},\n",
       " {'section': 'gram4-superlative', 'correct': 0, 'incorrect': 56},\n",
       " {'section': 'gram5-present-participle', 'correct': 0, 'incorrect': 132},\n",
       " {'section': 'gram6-nationality-adjective', 'correct': 0, 'incorrect': 177},\n",
       " {'section': 'gram7-past-tense', 'correct': 0, 'incorrect': 132},\n",
       " {'section': 'gram8-plural', 'correct': 0, 'incorrect': 90},\n",
       " {'section': 'gram9-plural-verbs', 'correct': 0, 'incorrect': 132},\n",
       " {'section': 'total', 'correct': 4, 'incorrect': 1005}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context2vec.evaluate_analogy(input_path=\"data/questions-words.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
