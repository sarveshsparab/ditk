{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neuroner class implements named entity reognition using bi-directional LSTM's. The paper generates character enhances token embeddings as follows-\n",
    "\n",
    "- Character embeddings are passed through BLSTM\n",
    "- The output of BLSTM is combined with word embeddings to get character enhanced token embeddings\n",
    "\n",
    "The character enhanced token embeddings are passed through another BLSTM to generate predictions for each token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the `neuroner` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neuroner import neuroner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate object of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_model': 1, 'use_pretrained_model': 0, 'pretrained_model_folder': './trained_models/conll_2003_en/', 'dataset_text_folder': './data/conll2003/en', 'main_evaluation_mode': 'bio', 'output_folder': './output', 'use_character_lstm': 1, 'character_embedding_dimension': 25, 'character_lstm_hidden_state_dimension': 25, 'token_pretrained_embedding_filepath': './data/word_vectors/glove.6B.100d.txt', 'token_embedding_dimension': 100, 'token_lstm_hidden_state_dimension': 1, 'use_crf': 1, 'patience': 10, 'maximum_number_of_epochs': 1, 'optimizer': 'sgd', 'learning_rate': 0.005, 'gradient_clipping_value': 5.0, 'dropout_rate': 0.5, 'number_of_cpu_threads': 8, 'number_of_gpus': 0, 'experiment_name': 'test', 'output_scores': 0, 'tagging_format': 'bio', 'tokenizer': 'spacy', 'spacylanguage': 'en', 'remap_unknown_tokens_to_unk': 1, 'load_only_pretrained_token_embeddings': 0, 'load_all_pretrained_token_embeddings': 'False', 'check_for_lowercase': 1, 'check_for_digits_replaced_with_zeros': 1, 'freeze_token_embeddings': 0, 'debug': 0, 'verbose': 0, 'plot_format': 'pdf', 'reload_character_embeddings': 1, 'reload_character_lstm': 1, 'reload_token_embeddings': 1, 'reload_token_lstm': 1, 'reload_feedforward': 1, 'reload_crf': 1, 'parameters_filepath': './parameters.ini'}\n"
     ]
    }
   ],
   "source": [
    "ner = neuroner(parameters_filepath='./parameters.ini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give the path for train, dev and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputFiles = {'train': '/Users/lakshya/Desktop/CSCI-548/Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs-master/conll/train.txt',\n",
    "              'dev': '/Users/lakshya/Desktop/CSCI-548/Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs-master/conll/valid.txt',\n",
    "              'test': '/Users/lakshya/Desktop/CSCI-548/Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs-master/conll/test.txt'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and load the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = ner.read_dataset(inputFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Data\n",
    "\n",
    "Let's look at some data from train, dev and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-DOCSTART-', '-X-', '-X-', 'O'],\n",
       " [],\n",
       " ['EU', 'NNP', 'B-NP', 'B-ORG'],\n",
       " ['rejects', 'VBZ', 'B-VP', 'O'],\n",
       " ['German', 'JJ', 'B-NP', 'B-MISC'],\n",
       " ['call', 'NN', 'I-NP', 'O'],\n",
       " ['to', 'TO', 'B-VP', 'O'],\n",
       " ['boycott', 'VB', 'I-VP', 'O'],\n",
       " ['British', 'JJ', 'B-NP', 'B-MISC'],\n",
       " ['lamb', 'NN', 'I-NP', 'O'],\n",
       " ['.', '.', 'O', 'O'],\n",
       " []]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-DOCSTART-', '-X-', '-X-', 'O'],\n",
       " [],\n",
       " ['CRICKET', 'NNP', 'B-NP', 'O'],\n",
       " ['-', ':', 'O', 'O'],\n",
       " ['LEICESTERSHIRE', 'NNP', 'B-NP', 'B-ORG'],\n",
       " ['TAKE', 'NNP', 'I-NP', 'O'],\n",
       " ['OVER', 'IN', 'B-PP', 'O'],\n",
       " ['AT', 'NNP', 'B-NP', 'O'],\n",
       " ['TOP', 'NNP', 'I-NP', 'O'],\n",
       " ['AFTER', 'NNP', 'I-NP', 'O'],\n",
       " ['INNINGS', 'NNP', 'I-NP', 'O'],\n",
       " ['VICTORY', 'NN', 'I-NP', 'O'],\n",
       " ['.', '.', 'O', 'O'],\n",
       " []]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['dev'][0:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-DOCSTART-', '-X-', '-X-', 'O'],\n",
       " [],\n",
       " ['SOCCER', 'NN', 'B-NP', 'O'],\n",
       " ['-', ':', 'O', 'O'],\n",
       " ['JAPAN', 'NNP', 'B-NP', 'B-LOC'],\n",
       " ['GET', 'VB', 'B-VP', 'O'],\n",
       " ['LUCKY', 'NNP', 'B-NP', 'O'],\n",
       " ['WIN', 'NNP', 'I-NP', 'O'],\n",
       " [',', ',', 'O', 'O'],\n",
       " ['CHINA', 'NNP', 'B-NP', 'B-PER'],\n",
       " ['IN', 'IN', 'B-PP', 'O'],\n",
       " ['SURPRISE', 'DT', 'B-NP', 'O'],\n",
       " ['DEFEAT', 'NN', 'I-NP', 'O'],\n",
       " ['.', '.', 'O', 'O'],\n",
       " []]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['test'][0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the validity of BRAT-formatted train set... Done.\n",
      "Checking compatibility between CONLL and BRAT for train_compatible_with_brat set ... Done.\n",
      "Checking the validity of BRAT-formatted valid set... Done.\n",
      "Checking compatibility between CONLL and BRAT for valid_compatible_with_brat set ... Done.\n",
      "Checking the validity of BRAT-formatted test set... Done.\n",
      "Checking compatibility between CONLL and BRAT for test_compatible_with_brat set ... Done.\n",
      "Preprocessing dataset... done (29.72 seconds)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/lakshya/Downloads/ditk/extraction/named_entity/neuroner/entity_lstm.py:46: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/lakshya/Downloads/ditk/extraction/named_entity/neuroner/entity_lstm.py:146: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load token embeddings... done (0.98 seconds)\n",
      "number_of_token_original_case_found: 400000\n",
      "number_of_token_lowercase_found: 8770\n",
      "number_of_token_digits_replaced_with_zeros_found: 68\n",
      "number_of_token_lowercase_and_digits_replaced_with_zeros_found: 5\n",
      "number_of_loaded_word_vectors: 408843\n",
      "dataset.vocabulary_size: 409977\n",
      "\n",
      "Starting epoch 0\n",
      "Training completed in 0.00 seconds\n",
      "Evaluate model on the train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC     0.0196    0.0140    0.0163      3143\n",
      "       I-LOC     0.0067    0.1827    0.0130       427\n",
      "      B-MISC     0.0109    0.0791    0.0192      1466\n",
      "      I-MISC     0.0048    0.0320    0.0084       532\n",
      "       B-ORG     0.0264    0.2067    0.0469      2777\n",
      "       I-ORG     0.0000    0.0000    0.0000      1518\n",
      "       B-PER     0.0594    0.1869    0.0901      3018\n",
      "       I-PER     0.0235    0.1018    0.0382      2162\n",
      "\n",
      "   micro avg     0.0235    0.1072    0.0386     15043\n",
      "   macro avg     0.0189    0.1004    0.0290     15043\n",
      "weighted avg     0.0257    0.1072    0.0382     15043\n",
      "\n",
      "Evaluate model on the valid set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC     0.0328    0.0267    0.0294      1837\n",
      "       I-LOC     0.0052    0.1518    0.0100       257\n",
      "      B-MISC     0.0139    0.0998    0.0244       922\n",
      "      I-MISC     0.0061    0.0376    0.0105       346\n",
      "       B-ORG     0.0236    0.2364    0.0430      1341\n",
      "       I-ORG     0.0000    0.0000    0.0000       751\n",
      "       B-PER     0.0674    0.1987    0.1006      1842\n",
      "       I-PER     0.0201    0.0941    0.0331      1307\n",
      "\n",
      "   micro avg     0.0234    0.1161    0.0389      8603\n",
      "   macro avg     0.0211    0.1056    0.0314      8603\n",
      "weighted avg     0.0301    0.1161    0.0429      8603\n",
      "\n",
      "Evaluate model on the test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC     0.0268    0.0204    0.0231      1668\n",
      "       I-LOC     0.0030    0.0739    0.0058       257\n",
      "      B-MISC     0.0099    0.0855    0.0178       702\n",
      "      I-MISC     0.0053    0.0417    0.0094       216\n",
      "       B-ORG     0.0301    0.2288    0.0533      1661\n",
      "       I-ORG     0.0000    0.0000    0.0000       835\n",
      "       B-PER     0.0565    0.1905    0.0871      1617\n",
      "       I-PER     0.0205    0.0934    0.0336      1156\n",
      "\n",
      "   micro avg     0.0237    0.1132    0.0392      8112\n",
      "   macro avg     0.0190    0.0918    0.0288      8112\n",
      "weighted avg     0.0270    0.1132    0.0398      8112\n",
      "\n",
      "\n",
      "Starting epoch 1\n",
      "Training completed in 1086.57 seconds\n",
      "Evaluate model on the train set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC     0.5782    0.4703    0.5187      3143\n",
      "       I-LOC     0.0000    0.0000    0.0000       427\n",
      "      B-MISC     0.0000    0.0000    0.0000      1466\n",
      "      I-MISC     0.0000    0.0000    0.0000       532\n",
      "       B-ORG     0.4643    0.2953    0.3610      2777\n",
      "       I-ORG     0.4373    0.1700    0.2448      1518\n",
      "       B-PER     0.5755    0.4987    0.5344      3018\n",
      "       I-PER     0.5783    0.6984    0.6327      2162\n",
      "\n",
      "   micro avg     0.5495    0.3703    0.4425     15043\n",
      "   macro avg     0.3292    0.2666    0.2864     15043\n",
      "weighted avg     0.4492    0.3703    0.3979     15043\n",
      "\n",
      "Evaluate model on the valid set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC     0.5379    0.4638    0.4981      1837\n",
      "       I-LOC     0.0000    0.0000    0.0000       257\n",
      "      B-MISC     0.0000    0.0000    0.0000       922\n",
      "      I-MISC     0.0000    0.0000    0.0000       346\n",
      "       B-ORG     0.3545    0.2289    0.2782      1341\n",
      "       I-ORG     0.2297    0.0639    0.1000       751\n",
      "       B-PER     0.6208    0.5261    0.5695      1842\n",
      "       I-PER     0.6249    0.7445    0.6795      1307\n",
      "\n",
      "   micro avg     0.5451    0.3660    0.4380      8603\n",
      "   macro avg     0.2960    0.2534    0.2657      8603\n",
      "weighted avg     0.4180    0.3660    0.3836      8603\n",
      "\n",
      "Evaluate model on the test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC     0.5770    0.4155    0.4831      1668\n",
      "       I-LOC     0.0000    0.0000    0.0000       257\n",
      "      B-MISC     0.0000    0.0000    0.0000       702\n",
      "      I-MISC     0.0000    0.0000    0.0000       216\n",
      "       B-ORG     0.4838    0.3143    0.3810      1661\n",
      "       I-ORG     0.4035    0.1653    0.2345       835\n",
      "       B-PER     0.5565    0.4842    0.5179      1617\n",
      "       I-PER     0.5622    0.6843    0.6172      1156\n",
      "\n",
      "   micro avg     0.5384    0.3608    0.4321      8112\n",
      "   macro avg     0.3229    0.2579    0.2792      8112\n",
      "weighted avg     0.4503    0.3608    0.3927      8112\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Finishing the experiment\n",
      "Trimming dataset.pickle..\n",
      "\tcharacter_indices\n",
      "\tcharacter_indices_padded\n",
      "\tcharacters\n",
      "\tlabel_indices\n",
      "\tlabel_vector_indices\n",
      "\tlabels\n",
      "\ttoken_indices\n",
      "\ttoken_lengths\n",
      "\ttokens\n",
      "\tinfrequent_token_indices\n",
      "\ttokens_mapped_to_unk\n"
     ]
    }
   ],
   "source": [
    "ner.train(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the ground truth from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ground = ner.convert_ground_truth(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./output/conll_2019-04-29_23-01-50-456390/output/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "predictions = ner.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview predictions\n",
    "\n",
    "Lets have a look at what predictions look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 6, 'SOCCER', 'O'),\n",
       " (None, 1, '-', 'O'),\n",
       " (None, 5, 'JAPAN', 'B-LOC'),\n",
       " (None, 3, 'GET', 'O'),\n",
       " (None, 5, 'LUCKY', 'O'),\n",
       " (None, 3, 'WIN', 'O'),\n",
       " (None, 1, ',', 'O'),\n",
       " (None, 5, 'CHINA', 'O'),\n",
       " (None, 2, 'IN', 'O'),\n",
       " (None, 8, 'SURPRISE', 'O'),\n",
       " (None, 6, 'DEFEAT', 'O'),\n",
       " (None, 1, '.', 'O')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall and f-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC     0.5770    0.4155    0.4831      1668\n",
      "       I-LOC     0.0000    0.0000    0.0000       257\n",
      "      B-MISC     0.0000    0.0000    0.0000       702\n",
      "      I-MISC     0.0000    0.0000    0.0000       216\n",
      "       B-ORG     0.4838    0.3143    0.3810      1661\n",
      "       I-ORG     0.4035    0.1653    0.2345       835\n",
      "       B-PER     0.5565    0.4842    0.5179      1617\n",
      "       I-PER     0.5622    0.6843    0.6172      1156\n",
      "\n",
      "   micro avg     0.5384    0.3608    0.4321      8112\n",
      "   macro avg     0.3229    0.2579    0.2792      8112\n",
      "weighted avg     0.4503    0.3608    0.3927      8112\n",
      "\n",
      "Precision: 0.5384473877851361, Recall: 0.3608234714003945, F1: 0.4320932979037497\n"
     ]
    }
   ],
   "source": [
    "P,R,F1 = ner.evaluate(predictions, ground)\n",
    "\n",
    "print('Precision: %s, Recall: %s, F1: %s'%(P,R,F1))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
