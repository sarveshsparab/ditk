{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Named Entity Recognition\n",
    "## Approach\n",
    "The neuralSequenceLabeler class implements NER using  CNN's, bi-directional LSTM's and a CRF layer . \n",
    "\n",
    "- Convolutional neural networks (CNNs) are used to encode character-level information of a word into its character-level representation. \n",
    "- Character- and word-level representations are combined  and fe them into bi-directional LSTM (BLSTM) to model context information of each word. \n",
    "- On top of BLSTM, a sequential CRF is used to jointly decode NER labels for the whole sentence\n",
    "\n",
    "The approach has been tried and executed on the benchmarks( CoNLL 2003, ontonotes 5.0 and CHEMDNER)  chosen by G6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_final import NeuralSequenceLabeler\n",
    "from utils import parseconfig\n",
    "from utils.conll2003_prepro import process_data\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = parseconfig.parseConfig()\n",
    "file_dict = {\"train\":os.path.join(config[\"raw_path\"], \"train1.txt\"),\"dev\":os.path.join(config[\"raw_path\"], \"valid1.txt\"),\"test\":os.path.join(config[\"raw_path\"], \"test1.txt\")}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate object of NeuralSequenceLabeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralSequenceLabeler =  NeuralSequenceLabeler(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 219554\n",
      "dev 55044\n",
      "test 50350\n"
     ]
    }
   ],
   "source": [
    "dataset = neuralSequenceLabeler.read_dataset(file_dict,\"ontonotes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inititalise metadata & preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params number: 6039690\n"
     ]
    }
   ],
   "source": [
    "train_set,dev_set,test_set,vocab = process_data(dataset,config)\n",
    "neuralSequenceLabeler.initialize_metadata(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['-DOCSTART-', '-X-', '-X-', 'O', '-', '-', '-', '-', '-', '-', '-', '-']]\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to the train method is as shown in the format below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['BRUSSELS', 'NNP', 'B-NP', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-'], ['1996-08-22', 'CD', 'I-NP', 'O', '-', '-', '-', '-', '-', '-', '-', '-']]\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the model file , if pre-saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in load model....\n",
      "\n",
      "\n",
      "Loading completed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    neuralSequenceLabeler.load_model()\n",
    "    print(\"Loading completed\")\n",
    "except:\n",
    "    print(\"Error loading the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-processing the dataset in the required format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = {\"train\": train_set, \"dev\":dev_set,\"test\":test_set }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14987\n",
      "3466\n",
      "3684\n"
     ]
    }
   ],
   "source": [
    "dataset = neuralSequenceLabeler.read_dataset_helper(file_dict,\"ontonotes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model using train/dev & test dataset splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Epoch 1/2:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 441s - Global Step: 750 - Train Loss: 3.2517   \n",
      "\n",
      "\n",
      "in predict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev dataset -- pre: 76.81, rec: 80.10, FB1: 78.42\n",
      " -- new BEST score on test dataset: 78.42\n",
      "Epoch 2/2:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 403s - Global Step: 1500 - Train Loss: 0.8516   \n",
      "\n",
      "\n",
      "in predict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev dataset -- pre: 81.09, rec: 80.79, FB1: 80.94\n",
      " -- new BEST score on test dataset: 80.94\n"
     ]
    }
   ],
   "source": [
    "neuralSequenceLabeler.train(dataset[\"train_set\"],dataset[\"dev_data\"],dataset[\"dev_set\"],dataset[\"test_set\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "in predict...\n"
     ]
    }
   ],
   "source": [
    "predictions_formatted = neuralSequenceLabeler.predict(dataset[\"test_set\"],\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, None, 'soccer', 'O'], [None, None, '-', 'O'], [None, None, 'japan', 'B-LOC'], [None, None, 'get', 'O'], [None, None, 'lucky', 'O'], [None, None, 'win', 'O'], [None, None, ',', 'O'], [None, None, 'china', 'B-LOC'], [None, None, 'in', 'O'], [None, None, 'surprise', 'O'], [None, None, 'defeat', 'O'], [None, None, '.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(predictions_formatted[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting  the predictions and groundtruth labels in order to evaluate benchmarks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "groundTruths = []\n",
    "words_list = []\n",
    "for i in range(len(predictions_formatted)):\n",
    "    predictions_sentence = []\n",
    "    groundTruths_sentence = []\n",
    "    words_list_sentence = []\n",
    "    for j in range(len(predictions_formatted[i])):\n",
    "\n",
    "        words_list_sentence.append(predictions_formatted[i][j][2])\n",
    "        predictions_sentence.append(predictions_formatted[i][j][3])\n",
    "\n",
    "    predictions.append(predictions_sentence)\n",
    "\n",
    "    words_list.append(words_list_sentence)\n",
    "for data in dataset[\"test_set\"]:\n",
    "    for tags,  seq_len in zip(data[\"tags\"], data[\"seq_len\"]):\n",
    "            tags = [neuralSequenceLabeler.rev_tag_dict[x] for x in tags[:seq_len]]\n",
    "            groundTruths.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the predictions and reporting the p,r, f1 scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test dataset -- pre: 81.09, rec: 80.79, FB1: 80.94\n"
     ]
    }
   ],
   "source": [
    "save_path = os.path.join(neuralSequenceLabeler.cfg[\"checkpoint_path\"], \"result.txt\")\n",
    "name = \"test\"\n",
    "score = neuralSequenceLabeler.evaluate(predictions, groundTruths,words_list, save_path,name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
