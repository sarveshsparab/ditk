{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "## Approach\n",
    "The sequence_lableler_final class implements NER using  language modeling as a secondary objective , which improves the performance of the primary sequence labeling objective.\n",
    "\n",
    "- Input tokens mapped to word embeddings â€“ to obtain context specific representation for each word \n",
    "- biLSTM model built using tesnforflow is used with primary objective of sequence labeling and secondary objective as language modeling \n",
    "- CRF or softmax  used for prediction of label for each token \n",
    "\n",
    "The approach has been tried and executed on all three benchmarks( CoNLL 2003, ontonotes 5.0 and CHEMDNER)  chosen by G6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sequence_lableler_final import Sequence_labeler , parse_config\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"conf/fcepublic.conf\"\n",
    "temp_model_path = \"model/model\"\n",
    "config = parse_config(\"config\", path)\n",
    "file_paths = { \"train\": config[\"path_train\"] , \"dev\" : config[\"path_dev\"], \"test\" : config[\"path_test\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate an object of Sequence_labeler class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler = Sequence_labeler(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 91\n",
      "dev 30\n",
      "test 141\n"
     ]
    }
   ],
   "source": [
    "dataset = labeler.read_dataset(file_paths,\"ConLL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read and load the datasets for train , test and dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_formatted = dict()\n",
    "dataset_formatted[\"train\"] = labeler.data_formatted(dataset[\"train\"])\n",
    "dataset_formatted[\"dev\"] = labeler.data_formatted(dataset[\"dev\"])\n",
    "dataset_formatted[\"test\"] = labeler.data_formatted(dataset[\"test\"])\n",
    "data_train, data_dev, data_test = dataset_formatted[\"train\"],dataset_formatted[\"dev\"],dataset_formatted[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "building the vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Yes', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(15)'], ['did', 'VBD', '(VP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'do', '01', '-', 'Linda_Hamilton', '(V*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '-']]\n"
     ]
    }
   ],
   "source": [
    "print(data_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all labels:  Counter({'O': 199, 'I-WORK_OF_ART': 17, 'B-PERSON': 9, 'B-WORK_OF_ART': 6, 'I-PERSON': 3, 'I-FAC': 3, 'B-ORDINAL': 2, 'B-GPE': 1, 'TRUE_LABEL': 1, 'B-CARDINAL': 1, 'B-FAC': 1})\n"
     ]
    }
   ],
   "source": [
    "labeler.build_vocabs(data_train, data_dev, data_test, config[\"preload_vectors\"])\n",
    "labeler.construct_network()\n",
    "labeler.initialize_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading word embeddings and models preloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_preloaded_embeddings: 86\n"
     ]
    }
   ],
   "source": [
    "if config[\"preload_vectors\"] != None:\n",
    "    labeler.preload_word_embeddings(config[\"preload_vectors\"])\n",
    "if config[\"load\"] != None and len(config[\"load\"])  > 0 and os.path.exists(config[\"load\"]):\n",
    "    try:\n",
    "        labeler.load_model(labeler.session, temp_model_path)\n",
    "    except:\n",
    "        print(\"error in loading the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "current_learningrate: 1.0\n",
      "precision:  0.7777777777777778  recall:  0.9545454545454546  F1 :  0.8571428571428572\n",
      "best_epoch: 0\n",
      "EPOCH: 1\n",
      "current_learningrate: 1.0\n",
      "precision:  0.7857142857142857  recall:  1.0  F1 :  0.88\n",
      "best_epoch: 1\n",
      "EPOCH: 2\n",
      "current_learningrate: 1.0\n",
      "precision:  0.7857142857142857  recall:  1.0  F1 :  0.88\n",
      "best_epoch: 1\n",
      "EPOCH: 3\n",
      "current_learningrate: 1.0\n",
      "precision:  0.7857142857142857  recall:  1.0  F1 :  0.88\n",
      "best_epoch: 1\n"
     ]
    }
   ],
   "source": [
    "labeler.train(data_train,data_dev,temp_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_formatted = labeler.predict(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions are printed in the format [start index, span, token, token type] - \n",
    "The first two indices are None in this case for all predictions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, None, 'but', 'O'], [None, None, 'I', 'O'], [None, None, 'am', 'O'], [None, None, 'not', 'O'], [None, None, 'selling', 'O'], [None, None, 'medicine', 'O'], [None, None, 'or', 'O'], [None, None, 'pharmaceuticals', 'O'], [None, None, '/.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(predictions_formatted[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = 0\n",
    "predicted_labels = []\n",
    "groundTruths = []\n",
    "\n",
    "for i in range(len(predictions_formatted)):\n",
    "    predicted_labels_sent = []\n",
    "    groundTruths_sent = []\n",
    "    for j in range(len(predictions_formatted[i])):\n",
    "        predicted_labels_sent.append(labeler.label2id[predictions_formatted[i][j][-1]])\n",
    "\n",
    "    predicted_labels.append(predicted_labels_sent)\n",
    "\n",
    "\n",
    "for i in data_test:\n",
    "    groundTruths_sent = []\n",
    "    for item in i : \n",
    "        groundTruths_sent.append(item)\n",
    "    groundTruths.append(groundTruths_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result.txt','w',encoding = 'utf-8') as f:\n",
    "    for i in range(len(data_test)):\n",
    "        for j in range(len(data_test[i])):\n",
    "\n",
    "\n",
    "            f.write(str(data_test[i][j][0])+\" \"+str(data_test[i][j][3])+ \" \" +  str(labeler.id2label[predicted_labels[i][j]]))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision,recall,f1 = labeler.evaluate(predicted_labels,groundTruths, cost,\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is on a  small sample dataset, actual numbers are reported in the slide deck "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7727272727272727 1.0 0.8717948717948718\n"
     ]
    }
   ],
   "source": [
    "print(precision,recall,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
