{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temp_subclass import NER_with_LS \n",
    "import os, joblib, re, pyhocon, warnings, copy, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input mandatory ... \n",
    "dataset_name = \"conll\" # conll / ontonotes\n",
    "ratio = (0.70, 0.15, 0.15)\n",
    "\n",
    "options = {}\n",
    "options[\"ratio\"] = ratio\n",
    "options[\"dataset_name\"] = dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Created myModel...\n"
     ]
    }
   ],
   "source": [
    "# 1. Create my model\n",
    "print(\"==Created myModel...\")\n",
    "myModel = NER_with_LS(dataset_name)\n",
    "file_dict = dict() # dict for data_path\n",
    "file_dict[\"train\"] = myModel.config.raw_path+\"/\"+dataset_name+\".train.txt\"\n",
    "file_dict[\"dev\"] = myModel.config.raw_path+\"/\"+dataset_name+\".dev.txt\"\n",
    "file_dict[\"test\"] = myModel.config.raw_path+\"/\"+dataset_name+\".test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Splited! \n"
     ]
    }
   ],
   "source": [
    "# Split data to 3 parts\n",
    "input_file_path = \"./data/test/sample.txt\"\n",
    "myModel.split_data_txt(input_file_path, file_dict, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Reading dataset\n"
     ]
    }
   ],
   "source": [
    "# 2. Read dataset for training\n",
    "print(\"==Reading dataset\")\n",
    "data = myModel.read_dataset(file_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Training myModel w/ training dataset...\n",
      "['ls', 'emb', 'caps', 'chars'] 128\n",
      "Creating batchers\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/_G1/tmp548/_GitCode/ner-with-ls/model.py:130: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv1d instead.\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/_G1/tmp548/_GitCode/ner-with-ls/model.py:134: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling1d instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/_G1/tmp548/_GitCode/ner-with-ls/model.py:73: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/_G1/tmp548/_GitCode/ner-with-ls/model.py:84: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/_G1/tmp548/_GitCode/ner-with-ls/model.py:90: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "| epoch   0 |   500/1112 batches| lr 0.01078 | ms/batch  6.85 |loss 5.153891\n",
      "| epoch   0 |  1000/1112 batches| lr 0.01078 | ms/batch  5.56 |loss 3.549551\n",
      "Epoch: 0001 cost= 3.321633600\n",
      "| epoch   1 |   500/1112 batches| lr 0.00593 | ms/batch  7.34 |loss 1.342201\n",
      "| epoch   1 |  1000/1112 batches| lr 0.00593 | ms/batch  7.56 |loss 1.278626\n",
      "Epoch: 0002 cost= 1.264953627\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models/conll\n",
      "model restored\n"
     ]
    }
   ],
   "source": [
    "# 3. Train the model \n",
    "print(\"==Training myModel w/ training dataset...\")\n",
    "myModel.train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Saved model...\n",
      "INFO:tensorflow:Restoring parameters from models/conll\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4-1. saved model\n",
    "print(\"==Saved model...\")\n",
    "myModel.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Load model...\n",
      "INFO:tensorflow:Restoring parameters from models/conll\n"
     ]
    }
   ],
   "source": [
    "# 4-2. restore model\n",
    "print(\"==Load model...\")\n",
    "myModel.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Predict Test data...\n",
      "add_predict: ['ls', 'emb', 'caps', 'chars'] 128\n",
      "INFO:tensorflow:Restoring parameters from models/conll\n",
      "model restored\n",
      "len of pred_labels:  2177\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Predict\n",
    "print(\"==Predict Test data...\")\n",
    "pred_labels = myModel.predict(data[\"test\"])\n",
    "print(\"len of pred_labels: \", len(pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Getting ground truth data...\n",
      "len of ground_truth_labels:  2177\n"
     ]
    }
   ],
   "source": [
    "# 6. Get truth labels\n",
    "print(\"==Getting ground truth data...\")\n",
    "ground_truth_labels = myModel.convert_ground_truth(data[\"test\"])\n",
    "print(\"len of ground_truth_labels: \", len(ground_truth_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Evaluate test data...\n",
      "==precision, recall, f1\n",
      "('84.75%;', '85.46%;', 85.1)\n"
     ]
    }
   ],
   "source": [
    "# 7. Evaluate test input data\n",
    "print(\"==Evaluate test data...\")\n",
    "scores = myModel.evaluate(pred_labels, ground_truth_labels)\n",
    "print(\"==precision, recall, f1\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/conll.test.output\n"
     ]
    }
   ],
   "source": [
    "output_file_path = myModel.config[\"output_path\"] + \".test.output\"\n",
    "print(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
