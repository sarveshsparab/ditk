# Holographic Embedding
## Paper Title
- Holographic Embeddings of Knowledge Graphs
##Full Citation
- Nickel, Maximilian, Lorenzo Rosasco, and Tomaso Poggio. "Holographic embeddings of knowledge graphs." Thirtieth Aaai conference on artificial intelligence. 2016.

## Original Code
https://github.com/mnick/scikit-kge

## Description
- The overall task of thie project is to generate holographic embeddings of all entities and relatins in a knowledge graph.The main method used by the project is employing circular correlation in a holographic model with associated memory to generate compositional vectors. Additionally, this project generates negative examples to train the model, to ensure that the model can be trained with non-existing examples to learn to represent the true knowledge graph better.
## Functions
- The read_dataset function receives a list of input data files paths and pre-process them to generate inputs for the model
- The learn_embedding function builds the model, trainer, and evaluator. Then, it generates embeddings for each relation and entity in the knowledge graph.
- The save_model and load_model functions saves and loads models respectively.
- The evaluate function evaluate the predictions generated by the model given pairs of subject and relation or pairs of relation and object. The evaluation methods are cosine similarity, MR, and Hits@.

## Dependencies
- numpy==1.16.2
- scikit-learn==0.20.3
- scipy==1.2.1
- sklearn==0.0

## Input and Output
- The inputs take by the project are tuples containing relation information
Sample:
```
/m/011yn5	/m/01pjr7	/film/film/starring./film/performance/actor
/m/04nrcg	/m/02sdk9v	/soccer/football_team/current_roster./soccer/football_roster_position/position
/m/07nznf	/m/014lc_	/film/actor/film./film/performance/film
```
where the first two columns denote entities and the third column denotes relation.
### Prediction 
- Input: (entity id, entity id, relation id) tuples
Sample:
```
12577	1142	7744
935	655	8353
6504	1001	3679
```
- Output: predicted subject ids given relation ids and object ids in test tuples, and
            predicted object ids given subject ids and relation ids in test tuples.
Sample:
```
7744
8353
3679
```
### Training 
- Input: (entity id, entity id, relation id) tuples
Sample:
```
12577	1142	7744
935	655	8353
6504	1001	3679
```
- Output: entity embeddings and relation embeddings (vectors), and a trained model
Sample:
```
[ 0.04084018  0.04070616  ...  0.01305078 -0.03485108]
```
## Evalution
### Benchmark datasets 
- WN18: WordNet is a knowledge graph that groups words into synonyms and provides lexical relationships between words. The WN18 dataset consists of a subset of WordNet, containing 40,943 entities, 18 relation types, and 151,442 triples.

- FB15k: Freebase is a large knowledge graph that stores general facts about the world. The FB15k dataset consists of a subset of Freebase, containing 14,951 entities, 1345 relation types, and 592,213 triples.

- Wikidata12k: Wikidata is a temporal knowledge graph from a preprocessed dataset of Wikidata. The Wikidata12k dataset consists of a subset of Wikidata, containing 12.5k entities, 24 relation types and 40k triples.

- YAGO11k: YAGO3 is a knowledge graph extracted from Wikipedia and other sources. The YAGO11k dataset consists of a subset of YAGO3, containing 10,623 entities, 10 relation types and 20.5k triples.

### Evaluation metrics
- Cosine Similarity: the overall cosine similarity between the predicted entities' embeddings and the correct entities' embeddings.
- MR: Mean Rank of the list of predictions
- MRR: Mean Reciprocal Rank of the list of predictions
- Hits@n: the ratio in which the correct entity occurs within the first n results, n = 1, 3, 10 in this project
### Results 

Benchmark     | cosine similarity |   MR    |  MRR   | Hits@1 | Hits@3 | Hits@10 |
------------- | ----------------- |-------- |------- | ------ | ------ | ------- |
WN18          |       0.527       |  763.51 | 0.935  |  92.9  |  94.0  |   94.3  |
FB15k         |       0.422       |  529.82 | 0.423  |  29.4  |  49.8  |   66.5  |
Wikidata12k   |       0.196       | 1852.60 | 0.143  |  35.6  |  41.1  |   45.9  |
YAGO12k       |       0.103       | 3214.32 | 0.396  |  11.7  |  14.8  |   19.5  |
## Repository Structure
```
HolE/
|__ main.py --> invoke the entire project
|__ base.py --> setting for the project
|__ Holographic_Embedding.py --> the class implemented for the project
|__ Graph_Embedding.ipynb --> jupyter notebook illustrating functions
|__ skge 
    |__ __init__.py --> initialization 
    |__actfun.py --> activaiton function
    |__ base.py --> general settings of trainer
    |__ HolE.py --> general settings of HolE model
    |__ param.py --> parameters
    |__ sample.py --> samplers for generating negative instances
    |__ util.py --> general functions 
|__ tests/
    |__ graph_embedding_test.py --> unittest of the project
    |__ test_input/ --> data used for unittest
        |__ train.txt
        |__ valid.txt
        |__ test.txt
|__ requirements.txt --> required packages
|__ recipe.txt --> the link of the project and the implemented classes
```
## How to run it
- In the main.py, give the path of train, validation and test datafiles.
- The project will be invoked by simply running the main.py
- - The input files should be passed together in a dictionary, like
```
fileNames = ["train.txt","valid.txt", "test.txt"]
```
- When the main function is executed, read_dataset function, learn_embeddings function, save_model function and evaluate function will be executed in order.
- To adjust the model, change the parameters in base.py under the HolE folder

## Demo
- [Sample notebook](./graph_embedding.ipynb)
- [Demo Video](https://youtu.be/RRnIsnlIumM)
