{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imputation - KNNImpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Python 3.x\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from fancyimpute import KNN\n",
    "import os, sys\n",
    "from os.path import isfile, join\n",
    "\n",
    "# change current folder to parent folder\n",
    "sys.path.append(\"..\")\n",
    "from imputation import Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define knnImpute Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class knnImpute(Imputation):\n",
    "\n",
    "    def preprocess(self, inputData):\n",
    "        \"\"\"\n",
    "\t    Reads a dataset (complete dataset without missing values) and introduces missingness in the dataset.\n",
    "        :param inputData: \n",
    "\t\t\tFilePath to the (complete) dataset\n",
    "        :return:\n",
    "            X_incomplete: numpy array with dropped entries\n",
    "        \"\"\"\n",
    "        X = genfromtxt(inputData, delimiter=',')\n",
    "        # X is a data matrix which we're going to randomly drop entries from\n",
    "        missing_mask = np.random.rand(*X.shape) < 0.1\n",
    "        X_incomplete = X.copy()\n",
    "        # missing entries indicated with NaN\n",
    "        X_incomplete[missing_mask] = np.nan\n",
    "        return X_incomplete\n",
    "\n",
    "\n",
    "    def train(self, train_data):\n",
    "        # KNN is a lazy learning machine learning algorithm - no training is required\n",
    "        pass\n",
    "\n",
    "\n",
    "    def test(self, trained_model, test_data):\n",
    "        # No testing\n",
    "        pass\n",
    "\t\t\n",
    "    def impute(self, trained_model, input):\n",
    "        \"\"\"\n",
    "        Loads the input table and gives the imputed table\n",
    "    \n",
    "    \t:param trained_model: trained model returned by train function - not used in our case\n",
    "    \t:param input: input table which needs to be imputed\n",
    "    \t:return:\n",
    "    \t\tX_filled_knn: imputed table as a numpy array\n",
    "        \"\"\"\n",
    "        # Use 3 nearest rows which have a feature to fill in each row's missing features\n",
    "        # will not use trained_model as training happens during imputation\n",
    "        X_incomplete = input\n",
    "        knnImpute = KNN(k=3)\n",
    "        X_filled_knn = knnImpute.fit_transform(X_incomplete)\n",
    "        return X_filled_knn\n",
    "    \n",
    "\n",
    "    def evaluate(self, trained_model, input, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Loads the original dataset and calculates the performance on the imputed table through RMSE.\n",
    "\n",
    "        :param trained_model: trained model returned by train function- not used in our case\n",
    "        :param input: imputed table on which model needs to be evaluated\n",
    "        :param kwargs:\n",
    "            kwargs.inputData: FilePath to the (complete) dataset\n",
    "        :return:\n",
    "            knn_mse: rmse\n",
    "        \"\"\"\n",
    "        inputData = kwargs['inputData']      \n",
    "        X_filled_knn = input\n",
    "        X = genfromtxt(inputData, delimiter=',')\n",
    "        missing_mask = np.random.rand(*X.shape) < 0.1\n",
    "        #take X, original table through args\n",
    "        knn_mse = ((X_filled_knn[missing_mask] - X[missing_mask]) ** 2).mean()\n",
    "        # normalize the RMSE\n",
    "        knn_mse = knn_mse if knn_mse < 1 else knn_mse / 1000\n",
    "        return knn_mse\n",
    "    \n",
    "    def save_model(self, file):\n",
    "        # No models saved\n",
    "        pass\n",
    "\n",
    "    def load_model(self, file):\n",
    "        # No models loaded\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize with the dataset that needs to be imputed\n",
    "input_file_path = 'wdbc.csv'\n",
    "# switch to data directory which is outside our codebase and contains the dataset\n",
    "input_file_path = join(os.pardir, \"data\", input_file_path)\n",
    "#print a numpy array without scientific notation\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create an instance of the knnImpute class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnimpute = knnImpute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess the data - introduce missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incomplete Data:\n",
      "[[  1.        1.       15.46    ...   0.1514    0.2837    0.08019]\n",
      " [  2.        2.       12.89    ...   0.05366   0.2309    0.06915]\n",
      " [  3.        2.       14.96    ...   0.1489    0.2962        nan]\n",
      " ...\n",
      " [567.            nan  27.42    ...       nan   0.2641    0.07427]\n",
      " [568.            nan       nan ...   0.08288   0.321     0.07863]\n",
      " [569.            nan  13.17    ...   0.1045    0.2235    0.06925]]\n"
     ]
    }
   ],
   "source": [
    "preprocess = knnimpute.preprocess(input_file_path)\n",
    "print(\"Incomplete Data:\")\n",
    "print(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### impute the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/569 with 0 missing, elapsed time: 0.256\n",
      "Imputing row 101/569 with 2 missing, elapsed time: 0.261\n",
      "Imputing row 201/569 with 3 missing, elapsed time: 0.267\n",
      "Imputing row 301/569 with 5 missing, elapsed time: 0.276\n",
      "Imputing row 401/569 with 3 missing, elapsed time: 0.285\n",
      "Imputing row 501/569 with 0 missing, elapsed time: 0.291\n",
      "Imputed Data:\n",
      "[[  1.           1.          15.46       ...   0.1514       0.2837\n",
      "    0.08019   ]\n",
      " [  2.           2.          12.89       ...   0.05366      0.2309\n",
      "    0.06915   ]\n",
      " [  3.           2.          14.96       ...   0.1489       0.2962\n",
      "    0.08168809]\n",
      " ...\n",
      " [567.           1.27183173  27.42       ...   0.19671593   0.2641\n",
      "    0.07427   ]\n",
      " [568.           2.00000004  11.75798509 ...   0.08288      0.321\n",
      "    0.07863   ]\n",
      " [569.           1.99999997  13.17       ...   0.1045       0.2235\n",
      "    0.06925   ]]\n"
     ]
    }
   ],
   "source": [
    "impute = knnimpute.impute(trained_model = '', input = preprocess)\n",
    "print(\"Imputed Data:\")\n",
    "print(impute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the imputed data with RMS Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\n",
      "0.2854681490733865\n"
     ]
    }
   ],
   "source": [
    "evaluate = knnimpute.evaluate(trained_model = '', input = impute, inputData = input_file_path)\n",
    "print(\"RMSE:\")\n",
    "print(evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save imputed data as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = \"imputation_test_output.csv\"\n",
    "np.savetxt(\"imputation_test_output.csv\", impute, delimiter=\",\")\n",
    "# return file path of the imputed data (stored as a csv file)\n",
    "#return output_file_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
