{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imputation - MIKNNImpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Python 3.x\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from fancyimpute import BiScaler, SoftImpute\n",
    "import os, sys\n",
    "from os.path import isfile, join\n",
    "\n",
    "# change current folder to parent folder\n",
    "sys.path.append(\"..\")\n",
    "from imputation import Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define miknnImpute Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class miknnImpute(Imputation):\n",
    "\n",
    "    def preprocess(self, inputData):\n",
    "        \"\"\"\n",
    "\t    Reads a dataset (complete dataset without missing values) and introduces missingness in the dataset.\n",
    "        :param inputData: \n",
    "\t\t\tFilePath to the (complete) dataset\n",
    "        :return:\n",
    "            X_incomplete: numpy array with dropped entries\n",
    "        \"\"\"\n",
    "        X = genfromtxt(inputData, delimiter=',')\n",
    "        # X is a data matrix which we're going to randomly drop entries from\n",
    "        missing_mask = np.random.rand(*X.shape) < 0.1\n",
    "        X_incomplete = X.copy()\n",
    "        # missing entries indicated with NaN\n",
    "        X_incomplete[missing_mask] = np.nan\n",
    "        return X_incomplete\n",
    "\n",
    "\n",
    "    def train(self, train_data):\n",
    "        # MIKNN - a variation of KNN is a lazy learning machine learning algorithm - no training is required\n",
    "        pass\n",
    "\n",
    "\n",
    "    def test(self, trained_model, test_data):\n",
    "        # No testing\n",
    "        pass\n",
    "\t\t\n",
    "    def impute(self, trained_model, input):\n",
    "        \"\"\"\n",
    "        Loads the input table and gives the imputed table\n",
    "    \n",
    "    \t:param trained_model: trained model returned by train function - not used in our case\n",
    "    \t:param input: input table which needs to be imputed\n",
    "    \t:return:\n",
    "    \t\tX_filled_softimpute: imputed table as a numpy array\n",
    "        \"\"\"\n",
    "        X_incomplete = input\n",
    "        softImpute = SoftImpute()\n",
    "        biscaler = BiScaler()\n",
    "        X_incomplete_normalized = biscaler.fit_transform(X_incomplete)\n",
    "        X_filled_softimpute_normalized = softImpute.fit_transform(X_incomplete_normalized)\n",
    "        X_filled_softimpute = biscaler.inverse_transform(X_filled_softimpute_normalized)\n",
    "        return X_filled_softimpute\n",
    "    \n",
    "\n",
    "    def evaluate(self, trained_model, input, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Loads the original dataset and calculates the performance on the imputed table through RMSE.\n",
    "\n",
    "        :param trained_model: trained model returned by train function- not used in our case\n",
    "        :param input: imputed table on which model needs to be evaluated\n",
    "        :param kwargs:\n",
    "            kwargs.inputData: FilePath to the (complete) dataset\n",
    "        :return:\n",
    "            softImpute_mse: rmse\n",
    "        \"\"\"\n",
    "        inputData = kwargs['inputData']\n",
    "        X_filled_softimpute = input\n",
    "        X = genfromtxt(inputData, delimiter=',')\n",
    "        missing_mask = np.random.rand(*X.shape) < 0.1\n",
    "        #take X, original table through args\n",
    "        softImpute_mse = ((X_filled_softimpute[missing_mask] - X[missing_mask]) ** 2).mean()\n",
    "        # normalize the RMSE\n",
    "        softImpute_mse = softImpute_mse if softImpute_mse < 1 else softImpute_mse / 1000\n",
    "        return softImpute_mse\n",
    "    \n",
    "    def save_model(self, file):\n",
    "        # No models saved\n",
    "        pass\n",
    "\n",
    "    def load_model(self, file):\n",
    "        # No models loaded\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize with the dataset that needs to be imputed\n",
    "input_file_path = 'wdbc.csv'\n",
    "# switch to data directory which is outside our codebase and contains the dataset\n",
    "input_file_path = join(os.pardir, \"data\", input_file_path)\n",
    "#print a numpy array without scientific notation\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create an instance of the miknnImpute class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "miknnimpute = miknnImpute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess the data - introduce missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incomplete Data:\n",
      "[[      nan   1.       15.46    ...   0.1514    0.2837    0.08019]\n",
      " [  2.            nan  12.89    ...   0.05366   0.2309    0.06915]\n",
      " [  3.        2.       14.96    ...   0.1489    0.2962        nan]\n",
      " ...\n",
      " [567.        1.       27.42    ...   0.2625    0.2641        nan]\n",
      " [568.        2.       11.6     ...   0.08288       nan   0.07863]\n",
      " [569.        2.       13.17    ...   0.1045    0.2235    0.06925]]\n"
     ]
    }
   ],
   "source": [
    "preprocess = miknnimpute.preprocess(input_file_path)\n",
    "print(\"Incomplete Data:\")\n",
    "print(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### impute the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed Data:\n",
      "[[285.54897574   1.          15.46       ...   0.1514       0.2837\n",
      "    0.08019   ]\n",
      " [  2.           2.0342342   12.89       ...   0.05366      0.2309\n",
      "    0.06915   ]\n",
      " [  3.           2.          14.96       ...   0.1489       0.2962\n",
      "    0.08443819]\n",
      " ...\n",
      " [567.           1.          27.42       ...   0.2625       0.2641\n",
      "    0.09119885]\n",
      " [568.           2.          11.6        ...   0.08288      0.28030888\n",
      "    0.07863   ]\n",
      " [569.           2.          13.17       ...   0.1045       0.2235\n",
      "    0.06925   ]]\n"
     ]
    }
   ],
   "source": [
    "impute = miknnimpute.impute(trained_model = '', input = preprocess)\n",
    "print(\"Imputed Data:\")\n",
    "print(impute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the imputed data with RMS Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\n",
      "0.14860967309305653\n"
     ]
    }
   ],
   "source": [
    "evaluate = miknnimpute.evaluate(trained_model = '', input = impute, inputData = input_file_path)\n",
    "print(\"RMSE:\")\n",
    "print(evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save imputed data as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = \"imputation_test_output.csv\"\n",
    "np.savetxt(\"imputation_test_output.csv\", impute, delimiter=\",\")\n",
    "\n",
    "# return file path of the imputed data (stored as a csv file)\n",
    "#return output_file_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
