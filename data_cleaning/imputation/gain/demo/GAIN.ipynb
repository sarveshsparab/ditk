{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os import sys, path \n",
    "#Make Sure Parent File is stored properly for demo!\n",
    "from imputation import Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class GAIN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization for mini batch size, missing rate, hint rate, alpha and train rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAIN(Imputation):\n",
    "    def __init__(self, mb_size, p_miss, p_hint, alpha, train_rate):\n",
    "        self.mb_size= mb_size\n",
    "        self.p_miss = p_miss\n",
    "        self.p_hint = p_hint\n",
    "        self.alpha = alpha\n",
    "        self.train_rate = train_rate\n",
    "        self.H_Dim1 = None\n",
    "        self.H_Dim2 = None\n",
    "        print('Init Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for normalize, missingness introduction, train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAIN(GAIN):\n",
    "    def normalize(self, data, dimension):\n",
    "            Min_Val = np.zeros(dimension)\n",
    "            Max_Val = np.zeros(dimension)\n",
    "            for i in range(dimension):\n",
    "                Min_Val[i] = np.min(data[:,i])\n",
    "                data[:,i] = data[:,i] - np.min(data[:,i])\n",
    "                Max_Val[i] = np.max(data[:,i])\n",
    "                data[:,i] = data[:,i] / (np.max(data[:,i]) + 1e-6)  \n",
    "            print('Norm Done')              \n",
    "            return data   \n",
    "    \n",
    "    def introduce_missingness(self, Dim, No, Data):\n",
    "            p_miss_vec = self.p_miss * np.ones((Dim,1))\n",
    "            Missing = np.zeros((No, Dim))\n",
    "            for i in range(Dim):\n",
    "                A = np.random.uniform(0., 1., size = [len(Data),])\n",
    "                B = A > p_miss_vec[i]\n",
    "                Missing[:,i] = 1.*B\n",
    "            print('Missing Done')\n",
    "            return Missing\n",
    "    \n",
    "    def train_test_split(self, No, Data, Missing):\n",
    "        idx = np.random.permutation(No)\n",
    "        Train_No = int(No * self.train_rate)\n",
    "        Test_No = No - Train_No\n",
    "        trainX = Data[idx[:Train_No],:]\n",
    "        testX = Data[idx[Train_No:],:]\n",
    "        trainM = Missing[idx[:Train_No],:]\n",
    "        testM = Missing[idx[Train_No:],:]\n",
    "        print('Train/Test Done')\n",
    "        return trainX, testX, trainM, testM, Train_No, Test_No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing gain architecture, generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAIN(GAIN):\n",
    "    def gain_architecture(self, Dim):\n",
    "            X = tf.placeholder(tf.float32, shape = [None, Dim])\n",
    "            M = tf.placeholder(tf.float32, shape = [None, Dim])\n",
    "            H = tf.placeholder(tf.float32, shape = [None, Dim])\n",
    "            New_X = tf.placeholder(tf.float32, shape = [None, Dim])\n",
    "            D_W1 = tf.Variable(self.xavier_init([Dim*2, self.H_Dim1]))     # Data + Hint as inputs\n",
    "            D_b1 = tf.Variable(tf.zeros(shape = [ self.H_Dim1]))\n",
    "            D_W2 = tf.Variable(self.xavier_init([self.H_Dim1, self.H_Dim2]))\n",
    "            D_b2 = tf.Variable(tf.zeros(shape = [self.H_Dim2]))\n",
    "            D_W3 = tf.Variable(self.xavier_init([self.H_Dim2, Dim]))\n",
    "            D_b3 = tf.Variable(tf.zeros(shape = [Dim]))       # Output is multi-variate\n",
    "            theta_D = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3]\n",
    "            G_W1 = tf.Variable(self.xavier_init([Dim*2, self.H_Dim1]))     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "            G_b1 = tf.Variable(tf.zeros(shape = [self.H_Dim1]))\n",
    "            G_W2 = tf.Variable(self.xavier_init([self.H_Dim1, self.H_Dim2]))\n",
    "            G_b2 = tf.Variable(tf.zeros(shape = [self.H_Dim2]))\n",
    "            G_W3 = tf.Variable(self.xavier_init([self.H_Dim2, Dim]))\n",
    "            G_b3 = tf.Variable(tf.zeros(shape = [Dim]))\n",
    "            theta_G = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3]\n",
    "            print('Gain Arch Done')\n",
    "            return theta_D, theta_G, X, M, H, New_X\n",
    "    @staticmethod\n",
    "    def generator(new_x, m, G_W1, G_W2, G_W3, G_b1, G_b2, G_b3):\n",
    "        inputs = tf.concat(axis = 1, values = [new_x,m])  # Mask + Data Concatenate\n",
    "        G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n",
    "        G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)   \n",
    "        G_prob = tf.nn.sigmoid(tf.matmul(G_h2, G_W3) + G_b3) # [0,1] normalized Output\n",
    "        print('Gen Samp Done')\n",
    "        return G_prob\n",
    "            \n",
    "    @staticmethod\n",
    "    def discriminator(new_x, h, D_W1, D_W2, D_W3, D_b1, D_b2, D_b3):\n",
    "        inputs = tf.concat(axis = 1, values = [new_x,h])  # Hint + Data Concatenate\n",
    "        D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)  \n",
    "        D_h2 = tf.nn.relu(tf.matmul(D_h1, D_W2) + D_b2)\n",
    "        D_logit = tf.matmul(D_h2, D_W3) + D_b3\n",
    "        D_prob = tf.nn.sigmoid(D_logit)  # [0,1] Probability Output\n",
    "        print('Disc Sample Done')\n",
    "        return D_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Preprocessing input data : normalize, load, get dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAIN(GAIN):\n",
    "    def preprocess(self, inputData):\n",
    "            Data = np.loadtxt(inputData, delimiter=\",\",skiprows=1)\n",
    "            #Data = np.loadtxt(inputData, delimiter=\",\")\n",
    "            No = len(Data)\n",
    "            Dim = len(Data[0,:])\n",
    "            self.H_Dim1 = Dim\n",
    "            self.H_Dim2 = Dim\n",
    "            normalized_data = self.normalize(Data, Dim)\n",
    "            print('Preprocess Done')\n",
    "            return normalized_data, No, Dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static methods: xavier initialization, sample generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAIN(GAIN):\n",
    "    @staticmethod\n",
    "    def xavier_init(size):\n",
    "        in_dim = size[0]\n",
    "        xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "        return tf.random_normal(shape = size, stddev = xavier_stddev)\n",
    "    @staticmethod\n",
    "    def sample_M(m, n, p):\n",
    "        A = np.random.uniform(0., 1., size = [m, n])\n",
    "        B = A > p\n",
    "        C = 1.*B\n",
    "        return C    \n",
    "    @staticmethod\n",
    "    def sample_Z(m, n):\n",
    "        return np.random.uniform(0., 0.01, size = [m, n])        \n",
    "    @staticmethod\n",
    "    def sample_idx(m, n):\n",
    "         A = np.random.permutation(m)\n",
    "         idx = A[:n]\n",
    "         return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAIN(GAIN):    \n",
    "    def train(self, normalized_data, No, Dim):\n",
    "        missing_matrix  = self.introduce_missingness(Dim, No, normalized_data)\n",
    "        trainX, testX, trainM, testM, Train_No, Test_No= self.train_test_split(No, normalized_data, missing_matrix)\n",
    "        theta_D, theta_G, X, M, H, New_X = self.gain_architecture(Dim)\n",
    "        G_sample = self.generator(New_X, M, theta_G[0],theta_G[1], theta_G[2], theta_G[3], theta_G[4], theta_G[5])\n",
    "        Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "        D_prob = self.discriminator(Hat_New_X, H, theta_D[0], theta_D[1], theta_D[2], theta_D[3],theta_D[4],theta_D[5])\n",
    "        D_loss1 = -tf.reduce_mean(M * tf.log(D_prob + 1e-8) + (1-M) * tf.log(1. - D_prob + 1e-8)) \n",
    "        G_loss1 = -tf.reduce_mean((1-M) * tf.log(D_prob + 1e-8))\n",
    "        MSE_train_loss = tf.reduce_mean((M * New_X - M * G_sample)**2) / tf.reduce_mean(M)\n",
    "        D_loss = D_loss1\n",
    "        G_loss = G_loss1 + gain_obj.alpha * MSE_train_loss\n",
    "        MSE_test_loss = tf.reduce_mean(((1-M) * X - (1-M)*G_sample)**2) / tf.reduce_mean(1-M)\n",
    "        D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
    "        G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for it in tqdm(range(5000)):    \n",
    "            mb_idx = gain_obj.sample_idx(Train_No, gain_obj.mb_size)\n",
    "            X_mb = trainX[mb_idx,:]      \n",
    "            Z_mb = gain_obj.sample_Z(gain_obj.mb_size, Dim) \n",
    "            M_mb = trainM[mb_idx,:]  \n",
    "            H_mb1 = gain_obj.sample_M(gain_obj.mb_size, Dim, 1-gain_obj.p_hint)\n",
    "            H_mb = M_mb * H_mb1    \n",
    "            New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce    \n",
    "            _, D_loss_curr = sess.run([D_solver, D_loss1], feed_dict = {M: M_mb, New_X: New_X_mb, H: H_mb})\n",
    "            _, G_loss_curr, MSE_train_loss_curr, MSE_test_loss_curr = sess.run([G_solver, G_loss1, MSE_train_loss, MSE_test_loss],\n",
    "                                                                           feed_dict = {X: X_mb, M: M_mb, New_X: New_X_mb, H: H_mb})\n",
    "            if it % 100 == 0:\n",
    "                print('Iter: {}'.format(it))\n",
    "                print('Train_loss: {:.4}'.format(np.sqrt(MSE_train_loss_curr)))\n",
    "                print('Test_loss: {:.4}'.format(np.sqrt(MSE_test_loss_curr)))\n",
    "                print()\n",
    "        return Test_No, testM, testX, MSE_test_loss, G_sample, sess, X, M, New_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test functions, impute, evaluate. [Evaluate results are provided in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAIN(GAIN):\n",
    "    def test(self, Test_No, testM, testX, MSE_test_loss, G_sample, sess, X, M, New_X):\n",
    "        Z_mb = gain_obj.sample_Z(Test_No, Dim) \n",
    "        M_mb = testM\n",
    "        X_mb = testX\n",
    "        New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "        MSE_final, Sample = sess.run([MSE_test_loss, G_sample], feed_dict = {X: testX, M: testM, New_X: New_X_mb})\n",
    "        print('Final Test RMSE: ' + str(np.sqrt(MSE_final)))\n",
    "        \n",
    "    def impute(self, trained_model, input):\n",
    "        pass\n",
    "    \n",
    "    def evaluate(self, trained_model, input):\n",
    "        pass  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function to access GAIN, initial params, and with dataset in .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Done\n",
      "Norm Done\n",
      "Preprocess Done\n",
      "Missing Done\n",
      "Train/Test Done\n",
      "Gain Arch Done\n",
      "Gen Samp Done\n",
      "Disc Sample Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 29/5000 [00:00<16:05,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Train_loss: 0.2802\n",
      "Test_loss: 0.2659\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 134/5000 [00:00<04:01, 20.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Train_loss: 0.1699\n",
      "Test_loss: 0.1777\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 244/5000 [00:01<01:09, 68.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "Train_loss: 0.1476\n",
      "Test_loss: 0.1476\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 325/5000 [00:01<00:35, 132.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 300\n",
      "Train_loss: 0.152\n",
      "Test_loss: 0.1465\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 432/5000 [00:01<00:22, 205.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 400\n",
      "Train_loss: 0.1319\n",
      "Test_loss: 0.154\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 539/5000 [00:02<00:20, 222.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "Train_loss: 0.1317\n",
      "Test_loss: 0.15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 641/5000 [00:02<00:18, 239.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 600\n",
      "Train_loss: 0.1203\n",
      "Test_loss: 0.1523\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 752/5000 [00:03<00:16, 264.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 700\n",
      "Train_loss: 0.1121\n",
      "Test_loss: 0.1333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 833/5000 [00:03<00:16, 253.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 800\n",
      "Train_loss: 0.1073\n",
      "Test_loss: 0.1377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 928/5000 [00:04<00:20, 195.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 900\n",
      "Train_loss: 0.1079\n",
      "Test_loss: 0.1406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1046/5000 [00:04<00:17, 227.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1000\n",
      "Train_loss: 0.1029\n",
      "Test_loss: 0.1467\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1117/5000 [00:04<00:20, 189.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1100\n",
      "Train_loss: 0.0897\n",
      "Test_loss: 0.1332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 1237/5000 [00:05<00:20, 185.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1200\n",
      "Train_loss: 0.09721\n",
      "Test_loss: 0.1295\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1333/5000 [00:06<00:16, 220.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1300\n",
      "Train_loss: 0.09611\n",
      "Test_loss: 0.1318\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 1426/5000 [00:06<00:16, 210.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1400\n",
      "Train_loss: 0.08711\n",
      "Test_loss: 0.1213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 1534/5000 [00:06<00:13, 254.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1500\n",
      "Train_loss: 0.08299\n",
      "Test_loss: 0.1314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1650/5000 [00:07<00:12, 271.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1600\n",
      "Train_loss: 0.08309\n",
      "Test_loss: 0.1448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 1733/5000 [00:07<00:12, 257.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1700\n",
      "Train_loss: 0.07892\n",
      "Test_loss: 0.1388\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1840/5000 [00:08<00:12, 249.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1800\n",
      "Train_loss: 0.08161\n",
      "Test_loss: 0.1289\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1952/5000 [00:08<00:11, 271.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1900\n",
      "Train_loss: 0.07863\n",
      "Test_loss: 0.1334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 2040/5000 [00:08<00:10, 276.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2000\n",
      "Train_loss: 0.08204\n",
      "Test_loss: 0.1414\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2122/5000 [00:09<00:12, 237.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2100\n",
      "Train_loss: 0.07398\n",
      "Test_loss: 0.1257\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 2227/5000 [00:09<00:11, 245.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2200\n",
      "Train_loss: 0.07824\n",
      "Test_loss: 0.1194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2328/5000 [00:10<00:11, 223.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2300\n",
      "Train_loss: 0.06992\n",
      "Test_loss: 0.1269\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 2436/5000 [00:10<00:10, 253.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2400\n",
      "Train_loss: 0.07251\n",
      "Test_loss: 0.1231\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2542/5000 [00:10<00:09, 255.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2500\n",
      "Train_loss: 0.07139\n",
      "Test_loss: 0.1156\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2646/5000 [00:11<00:09, 245.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2600\n",
      "Train_loss: 0.07362\n",
      "Test_loss: 0.1239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 2745/5000 [00:11<00:09, 234.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2700\n",
      "Train_loss: 0.07666\n",
      "Test_loss: 0.129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 2843/5000 [00:12<00:09, 237.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2800\n",
      "Train_loss: 0.07178\n",
      "Test_loss: 0.114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 2938/5000 [00:12<00:09, 209.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2900\n",
      "Train_loss: 0.07283\n",
      "Test_loss: 0.1272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 3029/5000 [00:13<00:09, 215.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3000\n",
      "Train_loss: 0.07336\n",
      "Test_loss: 0.1283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 3148/5000 [00:13<00:08, 222.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3100\n",
      "Train_loss: 0.07096\n",
      "Test_loss: 0.1277\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 3236/5000 [00:13<00:08, 205.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3200\n",
      "Train_loss: 0.06664\n",
      "Test_loss: 0.1215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 3321/5000 [00:14<00:08, 198.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3300\n",
      "Train_loss: 0.06717\n",
      "Test_loss: 0.1262\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3421/5000 [00:14<00:08, 183.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3400\n",
      "Train_loss: 0.06829\n",
      "Test_loss: 0.1309\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 3527/5000 [00:15<00:07, 207.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3500\n",
      "Train_loss: 0.06763\n",
      "Test_loss: 0.1291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3648/5000 [00:16<00:05, 228.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3600\n",
      "Train_loss: 0.06577\n",
      "Test_loss: 0.1238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 3720/5000 [00:16<00:05, 224.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3700\n",
      "Train_loss: 0.06368\n",
      "Test_loss: 0.1364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3828/5000 [00:16<00:05, 196.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3800\n",
      "Train_loss: 0.06413\n",
      "Test_loss: 0.141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3913/5000 [00:17<00:05, 189.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3900\n",
      "Train_loss: 0.06571\n",
      "Test_loss: 0.1199\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 4054/5000 [00:18<00:04, 210.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4000\n",
      "Train_loss: 0.07105\n",
      "Test_loss: 0.127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 4103/5000 [00:18<00:04, 207.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4100\n",
      "Train_loss: 0.06929\n",
      "Test_loss: 0.127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 4220/5000 [00:19<00:05, 144.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4200\n",
      "Train_loss: 0.06636\n",
      "Test_loss: 0.1215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 4343/5000 [00:19<00:03, 198.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4300\n",
      "Train_loss: 0.06702\n",
      "Test_loss: 0.1352\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 4443/5000 [00:20<00:02, 225.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4400\n",
      "Train_loss: 0.06947\n",
      "Test_loss: 0.1129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 4543/5000 [00:20<00:01, 240.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4500\n",
      "Train_loss: 0.06479\n",
      "Test_loss: 0.1262\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 4644/5000 [00:21<00:01, 244.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4600\n",
      "Train_loss: 0.07082\n",
      "Test_loss: 0.1297\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 4750/5000 [00:21<00:00, 255.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4700\n",
      "Train_loss: 0.06723\n",
      "Test_loss: 0.123\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 4832/5000 [00:21<00:00, 264.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4800\n",
      "Train_loss: 0.06602\n",
      "Test_loss: 0.136\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 4938/5000 [00:22<00:00, 256.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4900\n",
      "Train_loss: 0.06591\n",
      "Test_loss: 0.1221\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:22<00:00, 220.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test RMSE: 0.12433786\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "    gain_obj = GAIN(128, 0.2, 0.9, 10, 0.8)\n",
    "    normalized_data, No, Dim= gain_obj.preprocess('Letter.csv')\n",
    "    Test_No, testM, testX, MSE_test_loss, G_sample, sess, X, M, New_X = gain_obj.train(normalized_data, No, Dim)\n",
    "    gain_obj.test(Test_No, testM, testX, MSE_test_loss, G_sample, sess, X, M, New_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
